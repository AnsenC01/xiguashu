
### 聚类任务
在无监督学习中，训练样本的标记信息是未知的，目标是通过对无标记训练样本的学习来揭示数据的内在性质及规律，为进一步的数据分析提供基础，此类学习任务中研究最多，应用最广的是聚类。

聚类试图将数据集中的样本划分为若干个通常是不相交的子集，每个子集称为一个簇。通过这样的划分，每个簇可能对应于一些潜在的概念/类别。这些概念对聚类算法而言事先是未知的，聚类过程仅能自动形成簇结构，簇对应的概念语义由使用者把握和命名。

![%E5%9B%BE%E7%89%87.png](attachment:%E5%9B%BE%E7%89%87.png)

聚类既能作为一个单独过程，用于找寻数据内在的分布结构，也可作为分类等其他学习任务的前驱过程

### 性能度量
聚类性能度量亦称聚类有效性指标，聚类性能度量大致有两类，一类是将聚类结果与某个参考模型进行比较，称为外部指标，另一个是直接考察聚类结果而不利用任何参考模型，称为内部指标。

### 距离计算
距离度量的基本性质
* 非负性
* 同一性
* 对称性
* 直递性
![%E5%9B%BE%E7%89%87.png](attachment:%E5%9B%BE%E7%89%87.png)

将属性划分为连续属性和离散属性，前者在定义域上有无穷多个可能的取值，后者在定义域上是有限个取值。闵科夫斯基距离用于有序属性。

对无序属性可采用VDM![%E5%9B%BE%E7%89%87.png](attachment:%E5%9B%BE%E7%89%87.png)

![%E5%9B%BE%E7%89%87.png](attachment:%E5%9B%BE%E7%89%87.png)

### 原型聚类
原型聚类亦称基于原型的聚类，此类算法假设聚类结构能通过一组原型刻画，在现实聚类任务中极为常用。通常形式下，算法先对原型进行初始化，然后对原型进行迭代更新求解，采用不同的原型表示，不同的求解方式，将产生不同的算法。


#### k均值算法
![%E5%9B%BE%E7%89%87.png](attachment:%E5%9B%BE%E7%89%87.png)

![%E5%9B%BE%E7%89%87.png](attachment:%E5%9B%BE%E7%89%87.png)

#### 学习向量量化
与 k 均值算法类似，“学习向量量化” (Learning Vector Quantization，简称 LVQ)也是试图找到一组原型向量来刻画聚类结构， 但与一般聚类算法不同的是， LVQ 假设数据样本带有类别标记（标签是随机指定的），学习过程利用样本的这些监督信息来辅助聚类。![%E5%9B%BE%E7%89%87.png](attachment:%E5%9B%BE%E7%89%87.png)

#### 高斯混合聚类
通过学习概率密度函数的Gaussian Mixture Model (GMM) 与 k-means 类似，不过 GMM 除了用在 clustering 上之外，还经常被用于 density estimation。对于二者的区别而言简单地说，k-means 的结果是每个数据点被 assign 到其中某一个 cluster ，而 GMM 则给出这些数据点被 assign 到每个 cluster 的概率。
Gaussian Mixture Model ，就是假设数据服从 Mixture Gaussian Distribution 。每个 GMM 由 K 个 Gaussian 分布组成，每个 Gaussian 称为一个“Component”，这些 Component 线性加成在一起就组成了 GMM 的概率密度函数：
![%E5%9B%BE%E7%89%87.png](attachment:%E5%9B%BE%E7%89%87.png)

#### 密度聚类
DBSCAN(Density-Based Spatial Clustering of Applications with Noise，具有噪声的基于密度的聚类方法)是一种很典型的密度聚类算法，和K-Means，BIRCH这些一般只适用于凸样本集的聚类相比，DBSCAN既可以适用于凸样本集，也可以适用于非凸样本集。　DBSCAN是一种基于密度的聚类算法，这类密度聚类算法一般假定类别可以通过样本分布的紧密程度决定。同一类别的样本，他们之间的紧密相连的，也就是说，在该类别任意样本周围不远处一定有同类别的样本存在。

DBSCAN是基于一组邻域来描述样本集的紧密程度的，参数(ϵ, MinPts)用来描述邻域的样本分布紧密程度。其中，ϵ描述了某一样本的邻域距离阈值，MinPts描述了某一样本的距离为ϵ的邻域中样本个数的阈值。将样本点分为三类，定义如下：
![%E5%9B%BE%E7%89%87.png](attachment:%E5%9B%BE%E7%89%87.png)

![%E5%9B%BE%E7%89%87.png](attachment:%E5%9B%BE%E7%89%87.png)

#### 层次聚类
层次聚类(hierarchical clustering)试图在不同层次对数据集进行划分，从而形成树形的聚类结构。数据集的划分可采用"自底向上"的聚合策略，也可采用 “自顶向下” 的分拆策略。
AGNES 是一种采用自底向上聚合策略的层次聚类算法.AGNES（自底向上凝聚算法）算法的具体步骤如下所示：
![%E5%9B%BE%E7%89%87.png](attachment:%E5%9B%BE%E7%89%87.png)
